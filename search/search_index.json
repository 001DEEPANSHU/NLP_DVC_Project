{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the documentation of StackOverflow Tag Prediction Project Project Overview Stack Overflow is a Q&A website where we can post our queries or questions on a wide range of programming topics and get feedback from other users. You can visit the Github repository for this project here On Stack Overflow, each question must have a minimum of one tag. Tags are simple keywords( or we can say labels) assist in grouping the new query/question with others of a similar nature. It's critical that questions are accurately classified because doing so makes it simpler for everyone to identify the questions they're looking for and answer them. Here, I solved the Binary Classification problem of predicting questions asked on StackOverflow having \"Python\" tags. Question structure The question consists of 3 things: Title Body Tags We can build a model to predict the tag of the question given its \"Title\" and \"Body\".","title":"Home"},{"location":"#welcome-to-the-documentation-of-stackoverflow-tag-prediction-project","text":"","title":"Welcome to the documentation of StackOverflow Tag Prediction Project"},{"location":"#project-overview","text":"Stack Overflow is a Q&A website where we can post our queries or questions on a wide range of programming topics and get feedback from other users. You can visit the Github repository for this project here On Stack Overflow, each question must have a minimum of one tag. Tags are simple keywords( or we can say labels) assist in grouping the new query/question with others of a similar nature. It's critical that questions are accurately classified because doing so makes it simpler for everyone to identify the questions they're looking for and answer them. Here, I solved the Binary Classification problem of predicting questions asked on StackOverflow having \"Python\" tags. Question structure The question consists of 3 things: Title Body Tags We can build a model to predict the tag of the question given its \"Title\" and \"Body\".","title":"Project Overview"},{"location":"ToolsUsed/","text":"Tools Used I used the following technologies in this project 1. Github Actions GitHub Actions is a tool offered by GitHub built to automate software workflows. For instance, software developers use GitHub Actions to automate branch merges, for handling issues in GitHub, doing application tests, etc. In simple terms, Github Actions allows us to automate and run our CI workflows directly from Github. You can visit the Github repository for this project here To practice Github Actions, we have to add a .yaml file in the .workflows/github folder. This .yaml file generally consists of the followings: Name of the workflow by name: name of the workflow Workflow triggering event: on: [push] will trigger this workflow whenever a push is made to the branch Jobs and steps: #Example: jobs: run: runs-on: [ubuntu-latest] steps: - uses: actions/checkout@v2 2. Data Version Control(DVC) DVC brings agility, reproducibility, and collaboration into your existing data science workflow. I used DVC to automate the whole project workflow defined in sequential stages: Stage 1: Data Preparation Stage 2: Featurization Stage 3: Training Stage 4: Evaluation We can construct machine learning pipelines by defining individual stages in one or more dvc.yaml files. Stages constitute a pipeline when they connect with each other (forming a dependency graph) Snapshot of dvc.yaml file used in this project: stages: Data-Preparation: cmd: python src/stage_01_data_preparation.py deps: - src/stage_01_data_preparation.py - src/utils - xmldata/data.xml outs: - artifacts/prepared Featurization: cmd: python src/stage_02_featurization.py deps: - src/stage_02_featurization.py - src/utils - artifacts/prepared outs: - artifacts/features train: cmd: python src/stage_03_train.py deps: - src/stage_02_featurization.py - src/utils - artifacts/features outs: - artifacts/model/model.pkl evaluate: cmd: python src/stage_04_evaluate.py deps: - src/stage_04_evaluate.py - src/utils - artifacts/features/test.pkl - artifacts/model/model.pkl metrics: - scores.json: cache: false #No storage in cache plots: - prc.json: cache: false #No storage in cache x: recall y: precision - roc.json: cache: false #No storage in cache x: fpr y: tpr Some of the important DVC commands are: dvc repro command reproduce complete or partial pipelines by executing commands defined in their stages in the correct order. If we have already run dvc repro , DVC will rerun the stage where it encounters the first change. So, in case of no change, it will give the output as: dvc dag command displays this dependency graph in one or more pipelines, as defined in the dvc.yaml files found in the project. For more information please refer to the DVC's official website 3. Continuous Machine Learning(CML) CML stands for \"Continuous Machine Learning\" and is an awesome opensource tool by iterative.ai . It allows us to maintain continuous training and integrations workflows of models and significantly increases the productivity. It can be used to automate the project workflow, including model training and evaluation, comparing ML experiments across the project history, and monitoring changing datasets. We can create a CML workflow by creating a file named cml.yaml at .github/workflows which consists of: name: CML on: [push] jobs: run: runs-on: ubuntu-latest container: docker://ghcr.io/iterative/cml:0-dvc2-base1 steps: - uses: actions/checkout@v3 with: ref: ${{ github.event.pull_request.head.sha }} - name: Train model env: REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }} run: | pip install -r requirements.txt python train.py For more information please refer to the CML's official website 4. Iterative Studio Iterative Studio is a web application that we can access online. Using the power of leading open-source tools DVC, CML and Git, it enables us to manage data and machine learning models, run and track experiments, and visualize and share results. After signing up, we can connect the iterative studio to our project by \"Adding project\". The metrics can also be tracked and visualized:","title":"Tools used for version control"},{"location":"ToolsUsed/#tools-used","text":"I used the following technologies in this project","title":"Tools Used"},{"location":"ToolsUsed/#1-github-actions","text":"GitHub Actions is a tool offered by GitHub built to automate software workflows. For instance, software developers use GitHub Actions to automate branch merges, for handling issues in GitHub, doing application tests, etc. In simple terms, Github Actions allows us to automate and run our CI workflows directly from Github. You can visit the Github repository for this project here To practice Github Actions, we have to add a .yaml file in the .workflows/github folder. This .yaml file generally consists of the followings: Name of the workflow by name: name of the workflow Workflow triggering event: on: [push] will trigger this workflow whenever a push is made to the branch Jobs and steps: #Example: jobs: run: runs-on: [ubuntu-latest] steps: - uses: actions/checkout@v2","title":"1. Github Actions"},{"location":"ToolsUsed/#2-data-version-controldvc","text":"DVC brings agility, reproducibility, and collaboration into your existing data science workflow. I used DVC to automate the whole project workflow defined in sequential stages: Stage 1: Data Preparation Stage 2: Featurization Stage 3: Training Stage 4: Evaluation We can construct machine learning pipelines by defining individual stages in one or more dvc.yaml files. Stages constitute a pipeline when they connect with each other (forming a dependency graph) Snapshot of dvc.yaml file used in this project: stages: Data-Preparation: cmd: python src/stage_01_data_preparation.py deps: - src/stage_01_data_preparation.py - src/utils - xmldata/data.xml outs: - artifacts/prepared Featurization: cmd: python src/stage_02_featurization.py deps: - src/stage_02_featurization.py - src/utils - artifacts/prepared outs: - artifacts/features train: cmd: python src/stage_03_train.py deps: - src/stage_02_featurization.py - src/utils - artifacts/features outs: - artifacts/model/model.pkl evaluate: cmd: python src/stage_04_evaluate.py deps: - src/stage_04_evaluate.py - src/utils - artifacts/features/test.pkl - artifacts/model/model.pkl metrics: - scores.json: cache: false #No storage in cache plots: - prc.json: cache: false #No storage in cache x: recall y: precision - roc.json: cache: false #No storage in cache x: fpr y: tpr Some of the important DVC commands are: dvc repro command reproduce complete or partial pipelines by executing commands defined in their stages in the correct order. If we have already run dvc repro , DVC will rerun the stage where it encounters the first change. So, in case of no change, it will give the output as: dvc dag command displays this dependency graph in one or more pipelines, as defined in the dvc.yaml files found in the project. For more information please refer to the DVC's official website","title":"2. Data Version Control(DVC)"},{"location":"ToolsUsed/#3-continuous-machine-learningcml","text":"CML stands for \"Continuous Machine Learning\" and is an awesome opensource tool by iterative.ai . It allows us to maintain continuous training and integrations workflows of models and significantly increases the productivity. It can be used to automate the project workflow, including model training and evaluation, comparing ML experiments across the project history, and monitoring changing datasets. We can create a CML workflow by creating a file named cml.yaml at .github/workflows which consists of: name: CML on: [push] jobs: run: runs-on: ubuntu-latest container: docker://ghcr.io/iterative/cml:0-dvc2-base1 steps: - uses: actions/checkout@v3 with: ref: ${{ github.event.pull_request.head.sha }} - name: Train model env: REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }} run: | pip install -r requirements.txt python train.py For more information please refer to the CML's official website","title":"3. Continuous Machine Learning(CML)"},{"location":"ToolsUsed/#4-iterative-studio","text":"Iterative Studio is a web application that we can access online. Using the power of leading open-source tools DVC, CML and Git, it enables us to manage data and machine learning models, run and track experiments, and visualize and share results. After signing up, we can connect the iterative studio to our project by \"Adding project\". The metrics can also be tracked and visualized:","title":"4. Iterative Studio"},{"location":"stage1dataprep/","text":"Stage 1: Data Preparation - Converting the xml data to tsv data - Splitting the data into 7:3 train and test ratio - Selecting 3 columns as features: > row ID > Content(Title and Body) > Tags(Target to be predicted)","title":"Stage 1: Data Preparation"},{"location":"stage1dataprep/#stage-1-data-preparation","text":"- Converting the xml data to tsv data - Splitting the data into 7:3 train and test ratio - Selecting 3 columns as features: > row ID > Content(Title and Body) > Tags(Target to be predicted)","title":"Stage 1: Data Preparation"},{"location":"workflow/","text":"Project Workflow Workflow Diagram","title":"Project Workflow"},{"location":"workflow/#project-workflow","text":"","title":"Project Workflow"},{"location":"workflow/#workflow-diagram","text":"","title":"Workflow Diagram"}]}